{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d5f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "from hydra import initialize, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1f7351a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_analysis(base_path, single_test=False):\n",
    "    paths = list(\n",
    "        filter(lambda x: x is not None,\n",
    "        [path if path.is_dir() else None for path in Path(base_path).iterdir()]))\n",
    "\n",
    "    if single_test:\n",
    "        paths = [Path(base_path)]\n",
    "    \n",
    "    file = pd.read_csv(paths[0] / 'pred.csv').file\n",
    "\n",
    "    cols = [\"file\"]\n",
    "    cols.extend([f\"prognosis_{ind}\" for ind in range(len(list(paths)))])\n",
    "    preds = pd.DataFrame(columns=cols)\n",
    "\n",
    "    preds[\"file\"] = file\n",
    "\n",
    "    for ind, path_dir in enumerate(paths):\n",
    "        try:\n",
    "            pred = pd.read_csv(path_dir / 'pred.csv')\n",
    "            preds[f\"prognosis_{ind}\"] = pred.prognosis.values\n",
    "            preds[f\"prognosis_{ind}\"].replace('SEVERE', 1, inplace=True)\n",
    "            preds[f\"prognosis_{ind}\"].replace('MILD', 0, inplace=True)\n",
    "            \n",
    "            preds[\"prognosis_real\"] = pred[\"prognosis_real\"].values\n",
    "            preds[\"prognosis_real\"].replace('SEVERE', 1, inplace=True)\n",
    "            preds[\"prognosis_real\"].replace('MILD', 0, inplace=True)\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    modes = stats.mode(preds[[f\"prognosis_{ind}\" for ind, _ in enumerate(paths)]].values,\n",
    "                       axis=1)[0]\n",
    "    preds[\"prognosis_mode\"] = modes\n",
    "        \n",
    "    scores = []\n",
    "    \n",
    "    if single_test:\n",
    "        for _ in range(100):\n",
    "            indicies = np.random.choice(len(preds[\"prognosis_real\"].values),\n",
    "                                        size=len(preds[\"prognosis_real\"].values),\n",
    "                                        replace=True)\n",
    "            _reals = preds[\"prognosis_real\"][indicies]\n",
    "            _preds = preds[\"prognosis_0\"][indicies]\n",
    "            scores.append(balanced_accuracy_score(_reals, _preds))\n",
    "        \n",
    "        print('CV analysis results')\n",
    "        print(np.around(np.mean(scores), 3), '+/-', np.around(np.std(scores), 3),\n",
    "             \"\\tBA score (full train, on test | BOOTSTRAPPED)\")\n",
    "    \n",
    "        return\n",
    "        \n",
    "    for ind, path_dir in enumerate(paths):\n",
    "        if float == type(preds[f\"prognosis_{ind}\"].values[0]):\n",
    "            continue\n",
    "        scores.append(balanced_accuracy_score(preds[\"prognosis_real\"].values.astype(int),\n",
    "                                              preds[f\"prognosis_{ind}\"].values.astype(int)))\n",
    "        \n",
    "        \n",
    "    bs_scores = []\n",
    "    for _ in range(100):\n",
    "            indicies = np.random.choice(len(preds[\"prognosis_real\"].values),\n",
    "                                        size=10,\n",
    "                                        replace=True)\n",
    "            _reals = preds[\"prognosis_real\"][indicies].values.astype(int)\n",
    "            _preds = preds[\"prognosis_mode\"][indicies].values.astype(int)\n",
    "            bs_scores.append(balanced_accuracy_score(_reals, _preds))\n",
    "      \n",
    "    print('Test analysis results')\n",
    "    space = \" \"\n",
    "    print(np.around(np.mean(bs_scores), 3), '+/-', np.around(np.std(bs_scores), 3),\n",
    "          f'{10*space}BA score (CV test | MODE, BOOTSTRAPPED)')\n",
    "\n",
    "    print(np.around(np.mean(scores),3), '+/-', np.around(np.std(scores), 3),\n",
    "          f'{10*space}Balanced accuracy score (CV test)')\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5b1245a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv_analysis(base_path):\n",
    "    paths = list(filter(lambda x: x is not None, [path if path.is_dir() else None for path in\\\n",
    "         Path(base_path).iterdir()]))\n",
    "\n",
    "    file = pd.read_csv(paths[0] / 'pred_valid.csv').file\n",
    "\n",
    "    cols = [\"file\"]\n",
    "    cols.extend([f\"prognosis_{ind}\"for ind in range(len(list(paths)))])\n",
    "    preds = pd.DataFrame(columns=cols)\n",
    "\n",
    "    preds[\"file\"] = file\n",
    "\n",
    "    for ind, path_dir in enumerate(paths):\n",
    "        try:\n",
    "            pred = pd.read_csv(path_dir / 'pred_valid.csv')\n",
    "            preds[f\"prognosis_{ind}\"] = pred.prognosis\n",
    "            preds[f\"prognosis_{ind}_real\"] = pred[\"prognosis_real\"]\n",
    "            preds[f\"prognosis_{ind}\"].replace('SEVERE', 1, inplace=True)\n",
    "            preds[f\"prognosis_{ind}\"].replace('MILD', 0, inplace=True)\n",
    "            preds[f\"prognosis_{ind}_real\"].replace('SEVERE', 1, inplace=True)\n",
    "            preds[f\"prognosis_{ind}_real\"].replace('MILD', 0, inplace=True)\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for ind, path_dir in enumerate(paths):\n",
    "        scores.append(balanced_accuracy_score(preds[f\"prognosis_{ind}_real\"].values.astype(int),\n",
    "                                              preds[f\"prognosis_{ind}\"].values.astype(int)))\n",
    "\n",
    "    print('CV analysis results')\n",
    "    space = \" \"\n",
    "    print(np.around(np.mean(scores), 3), '+/-', np.around(np.std(scores), 3),\n",
    "          f'{10*space}Balanced accuracy score (CV)')\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b01fc513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test analysis results\n",
      "0.731 +/- 0.146           BA score (CV test | MODE, BOOTSTRAPPED)\n",
      "0.708 +/- 0.021           Balanced accuracy score (CV test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/ai4covid/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "## ORIGINAL COMPETITION SUBMISSION --> trained on full training set, many more models to reduce variance in pred.\n",
    "_ = run_test_analysis(base_path='/mnt/ncshare/ai4covid_hackathon/raw_output/checkpoints/ENSEMBLE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9c605e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test analysis results\n",
      "0.713 +/- 0.154           BA score (CV test | MODE, BOOTSTRAPPED)\n",
      "0.724 +/- 0.018           Balanced accuracy score (CV test)\n",
      "CV analysis results\n",
      "0.764 +/- 0.02           Balanced accuracy score (CV)\n"
     ]
    }
   ],
   "source": [
    "## PAPER CHKPT, with early stopping enabled --> on a single model basis, better than the first one\n",
    "_ = run_test_analysis('/mnt/ncshare/ai4covid_hackathon/raw_output/cross_val/checkpoints/CROSS_VAL_paper_v1_w_ES/')\n",
    "_ = run_cv_analysis('/mnt/ncshare/ai4covid_hackathon/raw_output/cross_val/checkpoints/CROSS_VAL_paper_v1_w_ES/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2b394b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV analysis results\n",
      "0.707 +/- 0.022 \tBA score (full train, on test | BOOTSTRAPPED)\n"
     ]
    }
   ],
   "source": [
    "_ = run_test_analysis('/mnt/ncshare/ai4covid_hackathon/raw_output/checkpoints/ES_2022-09-27_11:13:46.479571/',\n",
    "                  single_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8e9289fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test analysis results\n",
      "0.75 +/- 0.162           BA score (CV test | MODE, BOOTSTRAPPED)\n",
      "0.705 +/- 0.04           Balanced accuracy score (CV test)\n"
     ]
    }
   ],
   "source": [
    "_ = run_test_analysis('/mnt/ncshare/ai4covid_hackathon/raw_output/checkpoints/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "314cd2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test analysis results\n",
      "0.688 +/- 0.15           BA score (CV test | MODE, BOOTSTRAPPED)\n",
      "0.631 +/- 0.049           Balanced accuracy score (CV test)\n"
     ]
    }
   ],
   "source": [
    "_ = run_test_analysis('/mnt/ncshare/ai4covid_hackathon/raw_output/checkpoints_image_only/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9d6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
